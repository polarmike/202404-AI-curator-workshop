<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Classifier - Three Step Process</title>
    <!-- TensorFlow.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tensorflow/3.18.0/tf.min.js"></script>
    <!-- Fallback to direct CDN if the first one fails -->
    <script>
        if (typeof tf === 'undefined') {
            document.write('<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0/dist/tf.min.js"><\/script>');
        }
    </script>
    <!-- Lodash -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/lodash.js/4.17.21/lodash.min.js"></script>
    <!-- ElevenLabs Conversational Agent Widget Script -->
    <script src="https://elevenlabs.io/convai-widget/index.js" async type="text/javascript"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
        }
        .container {
            display: flex;
            flex-direction: column;
            gap: 20px;
        }
        /* Step indicator styles */
        .steps-container {
            display: flex;
            justify-content: space-between;
            margin-bottom: 30px;
        }
        .step {
            flex: 1;
            text-align: center;
            padding: 15px;
            background-color: #f0f0f0;
            border-radius: 5px;
            position: relative;
        }
        .step.active {
            background-color: #4CAF50;
            color: white;
            font-weight: bold;
        }
        .step.completed {
            background-color: #8BC34A;
            color: white;
        }
        .step:not(:last-child):after {
            content: '';
            position: absolute;
            top: 50%;
            right: -15px;
            width: 30px;
            height: 2px;
            background-color: #ddd;
            z-index: -1;
        }
        /* Main content area with sidebar layout */
        .main-content {
            display: flex;
            gap: 20px;
        }
        .sidebar {
            width: 300px;
            padding: 15px;
            border: 1px solid #ddd;
            border-radius: 5px;
            background-color: #f9f9f9;
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        .content-area {
            flex: 1;
            padding: 15px;
            border: 1px solid #ddd;
            border-radius: 5px;
            background-color: #f9f9f9;
        }
        #preview {
            max-width: 250px;
            max-height: 250px;
            margin-top: 10px;
            border-radius: 5px;
            box-shadow: 0 3px 6px rgba(0,0,0,0.16);
        }
        .preview-container {
            text-align: center;
            margin-bottom: 15px;
        }
        .step-content {
            display: none;
        }
        .active-step {
            display: block;
        }
        button {
            padding: 10px 15px;
            background-color: #2196F3;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 14px;
            margin: 5px;
        }
        button:hover {
            background-color: #0b7dda;
        }
        .button-container {
            display: flex;
            justify-content: space-between;
            margin-top: 20px;
        }
        button.disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        input[type="file"], input[type="text"], select {
            padding: 10px;
            margin: 5px 0;
            width: 100%;
            border: 1px solid #ddd;
            border-radius: 4px;
        }
        .instructions {
            background-color: #e8f4ff;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 20px;
        }
        .result-container {
            margin-top: 20px;
        }
        .loader {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #3498db;
            border-radius: 50%;
            width: 20px;
            height: 20px;
            animation: spin 2s linear infinite;
            display: inline-block;
            margin-left: 10px;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        .hidden {
            display: none;
        }
        .api-settings {
            background-color: #f0f0f0;
            padding: 15px;
            border-radius: 5px;
            margin: 10px 0;
        }
        .progress-indicator {
            height: 4px;
            width: 100%;
            background-color: #f0f0f0;
            margin-top: 10px;
        }
        .progress-bar {
            height: 100%;
            width: 0;
            background-color: #4CAF50;
            transition: width 0.3s ease;
        }
        .no-image-placeholder {
            width: 250px;
            height: 200px;
            display: flex;
            align-items: center;
            justify-content: center;
            background-color: #f0f0f0;
            border: 2px dashed #ccc;
            border-radius: 5px;
            color: #888;
            font-size: 16px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Image Classifier - Three Step Process</h1>
        
        <!-- Step indicators -->
        <div class="steps-container">
            <div id="step1" class="step active">
                <h3>Step 1</h3>
                <p>Upload Image</p>
            </div>
            <div id="step2" class="step">
                <h3>Step 2</h3>
                <p>Process & Analyze</p>
            </div>
            <div id="step3" class="step">
                <h3>Step 3</h3>
                <p>Interactive Chat</p>
            </div>
        </div>
        
        <!-- Main content area with sidebar layout -->
        <div class="main-content">
            <!-- Sidebar with image preview -->
            <div class="sidebar">
                <h3>Image Preview</h3>
                <div class="preview-container">
                    <div id="no-image" class="no-image-placeholder">
                        <p>No image uploaded</p>
                    </div>
                    <img id="preview" src="" alt="" style="display: none;">
                </div>
                <div id="image-info" style="display: none;">
                    <p id="image-name">Filename: </p>
                    <p id="image-size">Size: </p>
                </div>
                <div class="model-input" style="width: 100%;">
                    <label for="model-url">Teachable Machine Model URL:</label>
                    <input type="text" id="model-url" placeholder="https://teachablemachine.withgoogle.com/models/YOUR_MODEL_ID/model.json">
                </div>
            </div>
            
            <!-- Main content area -->
            <div class="content-area">
                <!-- Step 1 Content: Upload Image -->
                <div id="step1-content" class="step-content active-step">
                    <h2>Step 1: Upload Your Image</h2>
                    <div class="instructions">
                        <h3>Instructions:</h3>
                        <p>Select an image file to upload for classification. The model works best with clear images where the subject is prominently visible.</p>
                        <h3>Getting your Teachable Machine model URL:</h3>
                        <ol>
                            <li>Go to your model on <a href="https://teachablemachine.withgoogle.com/" target="_blank">Teachable Machine</a></li>
                            <li>Click "Export Model"</li>
                            <li>Select "Tensorflow.js" tab</li>
                            <li>Click "Upload my model" to host it on Teachable Machine servers</li>
                            <li>Copy the provided model URL</li>
                            <li>Add "model.json" to the end of the URL if not already present</li>
                        </ol>
                    </div>
                    <div class="upload-container">
                        <label for="image-upload">Select Image File:</label>
                        <input type="file" id="image-upload" accept="image/*">
                    </div>
                    <div class="button-container">
                        <div></div> <!-- Empty div for spacing -->
                        <button id="proceed-to-step2" disabled>Proceed to Analysis</button>
                    </div>
                </div>
                
                <!-- Step 2 Content: Process & Analyze -->
                <div id="step2-content" class="step-content">
                    <h2>Step 2: Process & Analyze Image</h2>
                    <div class="analysis-options">
                        <h3>Classification</h3>
                        <div id="classification-progress" class="progress-indicator">
                            <div id="classification-progress-bar" class="progress-bar"></div>
                        </div>
                        <div id="result-container" class="result-container">
                            <p id="result">Click "Classify Image" to see results.</p>
                        </div>
                        <button id="classify-button">Classify Image</button>
                        
                        <h3>Image Description</h3>
                        <div class="api-settings">
                            <h4>External AI Provider Settings</h4>
                            <div>
                                <label for="ai-provider">Select AI Provider:</label>
                                <select id="ai-provider">
                                    <option value="local">Local (Basic Description)</option>
                                    <option value="openai">OpenAI (GPT-4 Vision)</option>
                                    <option value="deepseek">DeepSeek AI</option>
                                </select>
                            </div>
                            <div id="api-key-container" style="display: none;">
                                <label for="api-key">API Key:</label>
                                <input type="password" id="api-key" placeholder="Enter your API key">
                            </div>
                        </div>
                        
                        <div id="description-container" class="result-container">
                            <p id="image-description">Click "Generate Description" to analyze the image.</p>
                            <div id="description-loader" style="display: none;">
                                <span class="loader"></span> Generating description...
                            </div>
                        </div>
                        <button id="generate-description" disabled>Generate Image Description</button>
                    </div>
                    <div class="button-container">
                        <button id="back-to-step1">Back to Upload</button>
                        <button id="proceed-to-step3" disabled>Proceed to Chat</button>
                    </div>
                </div>
                
                <!-- Step 3 Content: Interactive Chat -->
                <div id="step3-content" class="step-content">
                    <h2>Step 3: Interact with AI Assistant</h2>
                    <div class="instructions">
                        <p>Ask the AI assistant about your image classification results and description. You can inquire about:</p>
                        <ul>
                            <li>Details about the classification results</li>
                            <li>Explanations of the image features</li>
                            <li>More information about detected objects</li>
                            <li>Suggestions based on the image content</li>
                        </ul>
                    </div>
                    <div id="agent-container">
                        <!-- Agent will be loaded here dynamically after classification -->
                        <elevenlabs-convai id="elevenlabs-agent" agent-id="dViYEOHPVrCL4viF7cij" dynamic-variables='{"classification_results": "No classification performed yet", "image_description": "No image analyzed yet"}'></elevenlabs-convai>
                    </div>
                    <div class="button-container">
                        <button id="back-to-step2">Back to Analysis</button>
                        <button id="reset-process">Start Over</button>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Global variables
        let classificationResult = null;
        let imageDescription = null;
        
        // DOM Elements
        const stepIndicators = [
            document.getElementById('step1'),
            document.getElementById('step2'),
            document.getElementById('step3')
        ];
        
        const stepContents = [
            document.getElementById('step1-content'),
            document.getElementById('step2-content'),
            document.getElementById('step3-content')
        ];
        
        // Navigation functions
        function showStep(stepNumber) {
            // Update step indicators
            stepIndicators.forEach((step, index) => {
                if (index + 1 < stepNumber) {
                    step.className = 'step completed';
                } else if (index + 1 === stepNumber) {
                    step.className = 'step active';
                } else {
                    step.className = 'step';
                }
            });
            
            // Show appropriate content
            stepContents.forEach((content, index) => {
                if (index + 1 === stepNumber) {
                    content.className = 'step-content active-step';
                } else {
                    content.className = 'step-content';
                }
            });
        }
        
        // Preview uploaded image
        document.getElementById('image-upload').addEventListener('change', function(event) {
            const file = event.target.files[0];
            if (file) {
                const reader = new FileReader();
                reader.onload = function(e) {
                    const preview = document.getElementById('preview');
                    preview.src = e.target.result;
                    preview.style.display = 'block';
                    document.getElementById('no-image').style.display = 'none';
                    
                    // Update image info
                    document.getElementById('image-info').style.display = 'block';
                    document.getElementById('image-name').textContent = `Filename: ${file.name}`;
                    document.getElementById('image-size').textContent = `Size: ${(file.size / 1024).toFixed(2)} KB`;
                    
                    // Enable proceed button
                    document.getElementById('proceed-to-step2').disabled = false;
                }
                reader.readAsDataURL(file);
            }
        });
        
        // Function to get image as base64
        function getImageAsBase64(imgElement) {
            const canvas = document.createElement('canvas');
            canvas.width = imgElement.naturalWidth;
            canvas.height = imgElement.naturalHeight;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(imgElement, 0, 0);
            return canvas.toDataURL('image/jpeg').split(',')[1]; // Remove data URL prefix
        }
        
        // Function to generate local description (no API)
        function generateLocalDescription(imgElement, classResults) {
            if (!classResults || classResults.length === 0) {
                return "No classification data available to generate a description.";
            }
            
            // Get the top prediction and its confidence
            const topClass = classResults[0].className;
            const topConfidence = classResults[0].probability;
            
            // Get image properties
            const imgWidth = imgElement.naturalWidth;
            const imgHeight = imgElement.naturalHeight;
            const aspectRatio = imgWidth / imgHeight;
            
            // Determine image orientation
            let orientation = "square";
            if (aspectRatio > 1.2) orientation = "landscape";
            if (aspectRatio < 0.8) orientation = "portrait";
            
            // Get color information by analyzing the image with canvas
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');
            canvas.width = 50;  // Small size for faster processing
            canvas.height = 50;
            ctx.drawImage(imgElement, 0, 0, canvas.width, canvas.height);
            const pixelData = ctx.getImageData(0, 0, canvas.width, canvas.height).data;
            
            // Calculate average brightness
            let totalBrightness = 0;
            for (let i = 0; i < pixelData.length; i += 4) {
                const r = pixelData[i];
                const g = pixelData[i + 1];
                const b = pixelData[i + 2];
                totalBrightness += (r + g + b) / 3;
            }
            const avgBrightness = totalBrightness / (pixelData.length / 4);
            
            // Determine if image is dark, medium, or bright
            let brightness = "medium brightness";
            if (avgBrightness < 85) brightness = "dark";
            if (avgBrightness > 170) brightness = "bright";
            
            // Build the description
            let description = "";
            
            if (topConfidence > 0.85) {
                description = `This image clearly shows a ${topClass}.`;
            } else if (topConfidence > 0.6) {
                description = `This image appears to show a ${topClass}.`;
            } else {
                description = `This image might contain a ${topClass}, but I'm not very confident.`;
            }
            
            // Add additional details about image qualities
            description += ` It is a ${orientation} image with ${brightness} overall.`;
            
            // Add information about other possible classes if they have significant probability
            const otherClasses = classResults.slice(1).filter(c => c.probability > 0.15);
            if (otherClasses.length > 0) {
                description += ` I can also see elements of ${otherClasses.map(c => c.className).join(", ")}.`;
            }
            
            return description;
        }
        
        // Function to get image description from OpenAI
        async function getOpenAIDescription(imgElement, classResults) {
            const apiKey = document.getElementById('api-key').value;
            if (!apiKey) {
                throw new Error('Please enter your OpenAI API key');
            }
            
            const base64Image = getImageAsBase64(imgElement);
            const topClasses = classResults.slice(0, 3).map(r => r.className).join(', ');
            
            const response = await fetch('https://api.openai.com/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${apiKey}`
                },
                body: JSON.stringify({
                    model: 'gpt-4-turbo',  // Updated to current vision model
                    messages: [
                        {
                            role: 'user',
                            content: [
                                {
                                    type: 'text',
                                    text: `Describe this image in detail. Our classification model identified these possible objects: ${topClasses}. Please verify and provide a detailed description of the image.`
                                },
                                {
                                    type: 'image_url',
                                    image_url: {
                                        url: `data:image/jpeg;base64,${base64Image}`
                                    }
                                }
                            ]
                        }
                    ],
                    max_tokens: 300
                })
            });
            
            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(`OpenAI API error: ${errorData.error?.message || response.statusText}`);
            }
            
            const data = await response.json();
            return data.choices[0].message.content;
        }
        
        // Function to get image description from DeepSeek
        async function getDeepSeekDescription(imgElement, classResults) {
            const apiKey = document.getElementById('api-key').value;
            if (!apiKey) {
                throw new Error('Please enter your DeepSeek API key');
            }
            
            const base64Image = getImageAsBase64(imgElement);
            const topClasses = classResults.slice(0, 3).map(r => r.className).join(', ');
            
            const response = await fetch('https://api.deepseek.com/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${apiKey}`
                },
                body: JSON.stringify({
                    model: 'deepseek-chat',
                    messages: [
                        {
                            role: 'user',
                            content: [
                                {
                                    type: 'text',
                                    text: `Describe this image in detail. Our classification model identified these possible objects: ${topClasses}. Please verify and provide a detailed description of the image.`
                                },
                                {
                                    type: 'image',
                                    image_url: {
                                        url: `data:image/jpeg;base64,${base64Image}`
                                    }
                                }
                            ]
                        }
                    ],
                    max_tokens: 300
                })
            });
            
            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(`DeepSeek API error: ${errorData.error?.message || response.statusText}`);
            }
            
            const data = await response.json();
            return data.choices[0].message.content;
        }
        
        // Load Teachable Machine model and classify image
        document.getElementById('classify-button').addEventListener('click', async function() {
            const modelURL = document.getElementById('model-url').value;
            const imageElement = document.getElementById('preview');
            const resultElement = document.getElementById('result');
            const progressBar = document.getElementById('classification-progress-bar');
            
            if (!modelURL) {
                resultElement.textContent = 'Please enter a model URL.';
                return;
            }
            
            if (imageElement.style.display === 'none') {
                resultElement.textContent = 'Please upload an image first.';
                return;
            }
            
            resultElement.textContent = 'Loading model and classifying image...';
            progressBar.style.width = '10%';
            
            try {
                // Check if TensorFlow.js is loaded
                if (typeof tf === 'undefined') {
                    throw new Error('TensorFlow.js could not be loaded. Please check your internet connection and try again.');
                }
                
                // Load the model
                const modelURL = document.getElementById('model-url').value;
                const modelFolderPath = modelURL.substring(0, modelURL.lastIndexOf('/') + 1);
                
                resultElement.textContent = 'Loading model... (This may take a few moments)';
                progressBar.style.width = '30%';
                
                try {
                    const model = await tf.loadLayersModel(modelURL);
                    progressBar.style.width = '50%';
                    
                    // Load metadata
                    resultElement.textContent = 'Loading metadata...';
                    const metadataURL = `${modelFolderPath}metadata.json`;
                    const metadataResponse = await fetch(metadataURL);
                    
                    progressBar.style.width = '70%';
                    
                    if (!metadataResponse.ok) {
                        throw new Error(`Failed to fetch metadata: ${metadataResponse.status} ${metadataResponse.statusText}`);
                    }
                    
                    const metadata = await metadataResponse.json();
                    
                    // Convert the image to a tensor
                    const tensor = tf.browser.fromPixels(imageElement)
                        .resizeNearestNeighbor([metadata.imageSize || 224, metadata.imageSize || 224])
                        .toFloat()
                        .div(tf.scalar(255))
                        .expandDims();
                    
                    progressBar.style.width = '80%';
                    
                    // Make prediction
                    resultElement.textContent = 'Analyzing image...';
                    const prediction = await model.predict(tensor).data();
                    
                    progressBar.style.width = '90%';
                    
                    // Process results
                    const results = Array.from(prediction)
                        .map((score, i) => ({ 
                            className: metadata.labels[i],
                            probability: score
                        }))
                        .sort((a, b) => b.probability - a.probability);
                    
                    // Store the result in the global variable
                    classificationResult = results;
                    
                    // Display results
                    let resultHTML = '<h3>Classification Results:</h3>';
                    resultHTML += '<ul>';
                    results.forEach(result => {
                        resultHTML += `<li>${result.className}: ${(result.probability * 100).toFixed(2)}%</li>`;
                    });
                    resultHTML += '</ul>';
                    
                    resultHTML += '<p><strong>Top prediction:</strong> ' + results[0].className + '</p>';
                    
                    resultElement.innerHTML = resultHTML;
                    progressBar.style.width = '100%';
                    
                    // Enable generate description button
                    document.getElementById('generate-description').disabled = false;
                    
                } catch (modelError) {
                    console.error('Model loading error:', modelError);
                    progressBar.style.width = '0%';
                    
                    // Provide more specific error messages
                    if (modelError.message.includes('fetch')) {
                        resultElement.innerHTML = `
                            <p>Error: Failed to fetch the model or metadata.</p>
                            <p><strong>Troubleshooting steps:</strong></p>
                            <ol>
                                <li>Check that your Teachable Machine model URL is correct and ends with "model.json"</li>
                                <li>Ensure your model is publicly accessible (not private)</li>
                                <li>Verify your internet connection is working</li>
                                <li>If using a custom-hosted model, ensure CORS is enabled on your server</li>
                            </ol>
                            <p>Detailed error: ${modelError.message}</p>
                        `;
                    } else {
                        resultElement.innerHTML = `Error: ${modelError.message}<br>Check the console for more details.`;
                    }
                    
                    throw modelError; // Re-throw to prevent further processing
                }
            } catch (error) {
                if (!resultElement.innerHTML.includes('Troubleshooting')) {
                    resultElement.innerHTML = `
                        <p>Error: ${error.message}</p>
                        <p>Please check your model URL, internet connection, and try again.</p>
                    `;
                }
                progressBar.style.width = '0%';
                console.error('Classification error:', error);
            }
        });
        
        // Handle generate description button click
        document.getElementById('generate-description').addEventListener('click', async function() {
            if (!classificationResult) {
                alert('Please classify the image first.');
                return;
            }
            
            const imageElement = document.getElementById('preview');
            if (!imageElement || !imageElement.complete || imageElement.naturalHeight === 0) {
                alert('Image not fully loaded. Please wait a moment and try again.');
                return;
            }
            
            const provider = document.getElementById('ai-provider').value;
            const descriptionElement = document.getElementById('image-description');
            const loader = document.getElementById('description-loader');
            
            // Show the loader
            loader.style.display = 'block';
            descriptionElement.textContent = 'Generating description...';
            
            try {
                switch (provider) {
                    case 'openai':
                        imageDescription = await getOpenAIDescription(imageElement, classificationResult);
                        break;
                    case 'deepseek':
                        imageDescription = await getDeepSeekDescription(imageElement, classificationResult);
                        break;
                    default:
                        // Local generation (no API call)
                        imageDescription = generateLocalDescription(imageElement, classificationResult);
                }
                
                // Display the description
                descriptionElement.textContent = imageDescription;
                
                // Enable proceed button
                document.getElementById('proceed-to-step3').disabled = false;
                
            } catch (error) {
                descriptionElement.textContent = `Error generating description: ${error.message}`;
                console.error('Description generation error:', error);
            } finally {
                // Hide the loader
                loader.style.display = 'none';
            }
        });
        
        // Function to update agent with classification results and description
        function updateAgent() {
            if (!classificationResult) {
                console.warn('No classification result to update the agent with.');
                return;
            }
            
            // If no description has been generated yet, generate one now
            if (!imageDescription) {
                const imageElement = document.getElementById('preview');
                if (imageElement && imageElement.complete && imageElement.naturalHeight > 0) {
                    imageDescription = generateLocalDescription(imageElement, classificationResult);
                    document.getElementById('image-description').textContent = imageDescription;
                } else {
                    imageDescription = "Image description could not be generated automatically.";
                }
            }
            
            // Format the classification results as a clean string
            let formattedResults = '';
            classificationResult.forEach((result, index) => {
                const percentage = (result.probability * 100).toFixed(1);
                formattedResults += `${result.className}: ${percentage}%`;
                if (index < classificationResult.length - 1) {
                    formattedResults += ', ';
                }
            });
            
            // Get the top prediction
            const topClass = classificationResult[0].className;
            const topProbability = (classificationResult[0].probability * 100).toFixed(1);
            
            // Create a dynamic variables object
            const dynamicVars = {
                classification_results: formattedResults,
                top_class: topClass,
                top_probability: topProbability,
                classification_time: new Date().toLocaleTimeString(),
                image_description: imageDescription
            };
            
            try {
                // Get the existing agent element
                const agentElement = document.getElementById('elevenlabs-agent');
                
                // Update the dynamic-variables attribute
                agentElement.setAttribute('dynamic-variables', JSON.stringify(dynamicVars));
                
            } catch (error) {
                console.error("Error updating agent:", error);
            }
        }
        
        // Event listeners